#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Sheet 6 - Clustering
\end_layout

\begin_layout Author
Jan Scheffczyk - 3242317
\begin_inset Newline newline
\end_inset

Leif Van Holland - 2563657
\begin_inset Newline newline
\end_inset

Oliver Leuschner - 3205025
\end_layout

\begin_layout Section*
Practical part
\end_layout

\begin_layout Standard
Please find the solution in the accompanying .py file.
\end_layout

\begin_layout Section*
Theoretical Part
\end_layout

\begin_layout Subsection*
Assignment 2) Convergence of k-means
\end_layout

\begin_layout Paragraph
a)
\end_layout

\begin_layout Standard
We perform only two operations both of which strictly decrease the cumulative
 distance and therefore the error function 
\begin_inset Formula $\mu$
\end_inset

.
 First we move the cluster centers to the mean of their respective point
 clouds which strictly decreases the the error function, The only exception
 would be if all the centers are already on their means, which is the terminatio
n criteria.
 Secondly points only change clusters if their distance to a center is reduced
 as a result.
\end_layout

\begin_layout Paragraph
b)
\end_layout

\begin_layout Standard
Given a finite number of 
\begin_inset Formula $k$
\end_inset

 clusters and 
\begin_inset Formula $N$
\end_inset

 points we have exactly 
\begin_inset Formula $k^{N}$
\end_inset

possible assignments which is a finite number.
\end_layout

\begin_layout Paragraph
c)
\end_layout

\begin_layout Standard
As the error function is strictly decreasing with each successive step we
 never get the same assignment twice.
 As we've just seen there is only a finite amount of possible assignments.
 Therefore the algorithm terminates after a finite amount of steps.
\end_layout

\begin_layout Subsection*
Assignment 3) Expectation Maximization
\end_layout

\begin_layout Subsubsection*
a)
\end_layout

\begin_layout Standard
The result strongly depends on the initialization, as the assignment of
 the data points are iteratively refined in subsequent steps.
 A weak initialization can therefore lead to slow convergence speeds or
 convergence towards a subpar optimum.
 The refinement of a GMM with EM occurs locally, because the assignment
 of a Gaussian distribution is dependent on the distance to the mean of
 the distribution and the following parameter maximization (M-step) is based
 on these local assignments.
\end_layout

\begin_layout Subsubsection*
b)
\end_layout

\begin_layout Standard
An incorrect number of clusters can cause hard-to-interpret results, as
 e.g.
 multiple clearly separated data clusters are be described by only one Gaussian
 or a single cluster is wrongly described by multiple (small) Gaussians.
\end_layout

\begin_layout Subsubsection*
c)
\end_layout

\begin_layout Standard
Two possibilities to improve convergence could be (a) to run the algorithm
 multiple times and select the best result and/or (b) to initialize it with
 a simple clustering algorithm like k-means.
\end_layout

\begin_layout Subsubsection*
d)
\end_layout

\begin_layout Standard
The sampling influence result/run-time, as the parameter maximization solely
 depends on the given data.
 A very sparse or ambiguous sampling can lead to slow convergence or convergence
 against a bad optimum.
\end_layout

\end_body
\end_document
